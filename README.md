# Kavak Chatbot - Prueba T√©cnica

Este proyecto es una prueba t√©cnica para la posici√≥n de AI Engineer en Kavak. Consiste en un chatbot inteligente capaz de responder preguntas frecuentes (RAG), buscar autos en un cat√°logo simulado y calcular opciones de financiamiento, todo orquestado mediante un grafo de decisiones stateless.

## Instalaci√≥n y Ejecuci√≥n Local

Para ejecutar el proyecto localmente, aseg√∫rate de tener Python 3.11+ instalado:

```bash
# 1. Crear entorno virtual
python3 -m venv venv
source venv/bin/activate

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Configurar variables de entorno
# Crea un archivo .env basado en settings.py o exporta tus variables (OPENAI_API_KEY)

# 4. Ejecutar servidor
uvicorn main:app --reload
```

## Demo Online

El servicio cuenta con una interfaz de chat web disponible para pruebas en:
üëâ **[https://kavaktest.nomada.dev/](https://kavaktest.nomada.dev/)**

## Integraci√≥n con Twilio
Para probar la integraci√≥n con WhatsApp (Twilio Sandbox):
1.  Env√≠a `join start-listen` al n√∫mero **+1 415 523 8886**.
2.  O usa este link directo: [https://wa.me/14155238886?text=join%20start-listen](https://wa.me/14155238886?text=join%20start-listen)

### Comandos Especiales
- **`/reset`**: Borra el historial de conversaci√≥n de tu n√∫mero. √ötil para pruebas cuando quieres empezar una nueva conversaci√≥n sin contexto anterior.

---

## Decisiones T√©cnicas

### RAG: Router Sem√°ntico + Recuperaci√≥n vs. B√∫squeda Vectorial Simple

En lugar de utilizar una b√∫squeda vectorial simple (RAG tradicional) donde se busca similitud contra toda la base de conocimiento, optamos por un enfoque de **Enrutamiento Sem√°ntico**:

1.  **Clasificaci√≥n**: Un LLM clasifica la intenci√≥n del usuario en categor√≠as predefinidas (e.g., `locations`, `financing`, `app_services`).
2.  **Recuperaci√≥n Dirigida**: Se recupera √∫nicamente el documento maestro correspondiente a esa categor√≠a.

**¬øPor qu√©?**
La b√∫squeda vectorial simple tiende a "alucinar" o traer contextos irrelevantes cuando la pregunta no tiene una similitud sem√°ntica fuerte con la respuesta correcta (e.g., preguntar por una ciudad que no existe en la lista de sedes). El enrutamiento hace la respuesta m√°s **predecible y controlada**: si el router clasifica como `locations` y la ciudad no est√° en el documento, el modelo puede responder con certeza que no tenemos sede ah√≠, en lugar de intentar adivinar bas√°ndose en palabras clave de otros documentos.

### Arquitectura "Stateless Graph"
En lugar de utilizar LangGraph como una m√°quina de estados persistente (donde el usuario "navega" entre nodos y el estado se guarda en `Checkpoints`), optamos por un enfoque donde **el grafo se ejecuta de principio a fin en cada petici√≥n**.

**Ventajas:**
- **Simplicidad**: No necesitamos gestionar persistencia compleja de grafos ni migraciones de estado si cambiamos la l√≥gica.
- **Robustez**: El estado se reconstruye en cada turno bas√°ndose en el historial de chat crudo.
- **Flexibilidad**: El router eval√∫a la intenci√≥n con todo el contexto actualizado en cada interacci√≥n.

üìñ **Ver detalles t√©cnicos en:** [`specs/GRAPH_README.md`](specs/GRAPH_README.md)

### Resoluci√≥n de Contexto (Financiamiento)
Para calcular financiamiento sin guardar estado, implementamos el nodo `resolve_car_context`. Este nodo analiza el historial de la conversaci√≥n con un LLM para identificar cu√°l fue el √∫ltimo auto mencionado (por el usuario o el bot) y extrae sus datos (Marca, Modelo, Precio).

*Nota: No es una soluci√≥n infalible (depende de la ventana de contexto y la precisi√≥n del modelo), pero para el objetivo de esta prueba t√©cnica funciona de manera excelente y evita la complejidad de una base de datos de sesiones.*

### Diagrama de Flujo
```ascii
                            [ START ]
                                |
                                v
                     +----------------------+
                     |   detect_intention   |
                     | (Router Classifier)  |
                     +----------------------+
                                |
          +---------------------+---------------------+---------------------+
          |                     |                     |                     |
          v                     v                     v                     v
   [ intent="faq" ]      [ intent="buy" ]    [ intent="financing" ]  [ intent="general" ]
          |                     |                     |                     |
          v                     v                     v                     v
 +------------------+  +------------------+  +-------------------+  +------------------+
 |    handle_faq    |  | reason_about_car |  |resolve_car_context|  |  handle_general  |
 | (RAG Retrieval)  |  | (Extract & Find) |  | (History Analysis)|  | (Chitchat/Help)  |
 +------------------+  +------------------+  +-------------------+  +------------------+
          |                     |                     |                     |
          |                     v                     v                     |
          |            +------------------+  +------------------+           |
          |            |respond_with_options|| handle_financing |           |
          |            | (Format Results) |  | (Calc Payments)  |           |
          |            +------------------+  +------------------+           |
          |                     |                     |                     |
          +---------------------+---------------------+---------------------+
                                |
                                v
                             [ END ]
```

## Base de Datos

üìñ **Documentaci√≥n completa en:** [`specs/DB_README.md`](specs/DB_README.md)

La aplicaci√≥n usa **SQLite** con autocarga de datos:
- **Cat√°logo de autos**: Cargado desde `specs/sample_caso_ai_engineer.csv`
- **Documentos RAG**: Generados con embeddings de OpenAI en startup

‚ö†Ô∏è **Nota**: La BD se auto-crea por practicidad en esta prueba t√©cnica. En producci√≥n real, la inicializaci√≥n de datos deber√≠a ser manejada por migraciones (Alembic) y scripts separados de la l√≥gica de la aplicaci√≥n.

## Notas para Revisi√≥n

- **Ventana de contexto**: El historial de chat est√° limitado a las √∫ltimas 24 horas para evitar contexto obsoleto. Esto es configurable en `utils.get_chat_history()`.
- **Fuzzy Matching**: El cat√°logo usa `thefuzz` para b√∫squedas flexibles (ej: "Jeta" ‚Üí "Jetta"). Umbral configurado en 70 puntos.

## Screenshots
### RAG
<table>
  <tr>
    <td><img src="specs/img/sedes.png" alt="Sedes" width="100%"/></td>
    <td><img src="specs/img/mantenimiento.png" alt="Mantenimiento" width="100%"/></td>
    <td><img src="specs/img/general.png" alt="General Info" width="100%"/></td>
  </tr>
</table>

### Compra de Carro
<table>
  <tr>
    <td><img src="specs/img/carro1.png" alt="Carro 1" width="100%"/></td>
    <td><img src="specs/img/carro2.png" alt="Carro 2" width="100%"/></td>
  </tr>
</table>

### Infraestructura
El despliegue se realiza con Kubernetes para aprovechar un servidor propio donde alojo mis proyectos UwU.
